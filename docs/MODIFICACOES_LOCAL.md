# Guia de Modifica√ß√µes para Execu√ß√£o Local

Este documento detalha todas as modifica√ß√µes feitas no c√≥digo original para permitir execu√ß√£o local mantendo compatibilidade com Databricks.

## Resumo das Modifica√ß√µes

| Componente | Modifica√ß√£o | Motivo |
|------------|-------------|--------|
| Bugsnag | Tornado opcional | N√£o necess√°rio localmente |
| AWS Utils | Mock criado | N√£o necess√°rio localmente |
| Imports | Relativos + Absolutos | Suportar import como m√≥dulo e execu√ß√£o direta |
| Credenciais | Via .env | Configura√ß√£o local segura |
| Vector Search | Config via .env | Conectar ao Databricks remotamente |

---

## Modifica√ß√µes Detalhadas

### 1. Bugsnag Tornado Opcional

**Arquivos modificados:**
- `src/gold/busca/main.py`
- `src/gold/busca/fuzzy_search.py`
- `src/gold/busca/semantic_search.py`

**Antes:**
```python
import bugsnag

# ... c√≥digo
bugsnag.notify(Exception("Teste"))
```

**Depois:**
```python
# Importa bugsnag apenas se dispon√≠vel
try:
    import bugsnag
except ImportError:
    # Mock do bugsnag para ambiente local
    class MockBugsnag:
        @staticmethod
        def notify(exception):
            pass  # Ignora notifica√ß√µes em ambiente local
    bugsnag = MockBugsnag()

# ... c√≥digo continua funcionando
bugsnag.notify(Exception("Teste"))  # N√£o d√° erro se bugsnag n√£o estiver instalado
```

**Benef√≠cio:** C√≥digo funciona sem instalar bugsnag (pacote usado apenas em produ√ß√£o).

---

### 2. AWS Utils Tornado Opcional

**Arquivo modificado:** `src/gold/busca/semantic_search.py`

**Antes:**
```python
from utils.aws_utils import secrets
```

**Depois:**
```python
# Tenta importar AWS utils (opcional - s√≥ usado em prod)
try:
    from utils.aws_utils import secrets
except (ImportError, ModuleNotFoundError):
    # Mock para ambiente local sem AWS
    class MockSecrets:
        @staticmethod
        def get_secret(secret_name):
            return {secret_name: None}
    secrets = MockSecrets()
```

**Benef√≠cio:** N√£o precisa de boto3 (AWS SDK) instalado localmente.

---

### 3. Imports Relativos e Absolutos

**Arquivos modificados:**
- `src/gold/busca/main.py`
- `src/gold/busca/fuzzy_search.py`
- `src/gold/busca/semantic_search.py`

**Problema:** Imports falhavam quando c√≥digo era importado como m√≥dulo.

**Solu√ß√£o:**

```python
# Tenta import relativo (quando importado como m√≥dulo)
try:
    from .fuzzy_search import *
    from .semantic_search import *
except ImportError:
    # Fallback para import absoluto (quando executado diretamente)
    from fuzzy_search import *
    from semantic_search import *
```

**Benef√≠cio:** Funciona tanto em `python test_local.py` quanto em `cd src/gold/busca && python main.py`.

---

### 4. Carregamento de Credenciais via .env

**Arquivo modificado:** `src/gold/busca/semantic_search.py`

**Adicionado:**
```python
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente para execu√ß√£o local
load_dotenv()
```

**Configura√ß√£o do Vector Search Client:**

```python
def _configure_vector_search_client(self):
    runner = str(os.getenv("WHO_IS_RUNNING_THIS"))

    # Se rodando localmente, configura com credenciais do .env
    if runner == "local" or (not host and runner not in ["ENDPOINT_NOTEBOOK", "ENDPOINT_MLFLOW"]):
        print("LOG: Running locally. Using credentials from .env file...")
        databricks_host = os.getenv("DATABRICKS_HOST")
        databricks_token = os.getenv("DATABRICKS_TOKEN")

        if not databricks_host or not databricks_token:
            raise ValueError(
                "DATABRICKS_HOST and DATABRICKS_TOKEN must be set in .env file.\n"
                "Copy .env.config to .env and fill in your credentials."
            )

        # Garante que o host tem https://
        if not databricks_host.startswith("https://"):
            databricks_host = f"https://{databricks_host}"

        return VectorSearchClient(
            workspace_url=databricks_host,
            personal_access_token=databricks_token,
            disable_notice=True
        )
```

**Benef√≠cio:** Credenciais n√£o ficam hardcoded no c√≥digo.

---

### 5. Dynamic Catalog Adaptado

**Arquivo modificado:** `src/utils/dynamic_cat/dynamic_catalog.py`

**Adicionado suporte para .env:**

```python
def get_host():
    """
    Retorna a URL do workspace Databricks atual.
    Se rodando localmente, retorna do .env.
    """
    # Se rodando localmente, pega do .env
    if os.getenv("WHO_IS_RUNNING_THIS") == "local" or not os.getenv("DATABRICKS_HOST"):
        load_dotenv()
        databricks_host = os.getenv("DATABRICKS_HOST", "")
        return databricks_host.replace("https://", "").replace("http://", "")

    # Se rodando no Databricks, pega do Spark
    spark = _spark()
    workspace_url = spark.conf.get("spark.databricks.workspaceUrl").lower()
    return workspace_url
```

---

### 6. Bloco de Teste no main.py

**Arquivo modificado:** `src/gold/busca/main.py`

**Antes:** C√≥digo de teste comentado, precisava descomentar manualmente.

**Depois:** Bloco execut√°vel autom√°tico:

```python
if __name__ == "__main__":
    import pandas as pd
    from dotenv import load_dotenv

    # Carrega credenciais do .env
    load_dotenv()
    os.environ["WHO_IS_RUNNING_THIS"] = "local"

    # Dados de teste
    data = {...}

    # Carrega o CSV
    file_csv = pd.read_csv("./books_search.csv", encoding="utf-8")

    # Executa a busca
    result = consolidation_function(data, file_csv, local=True)

    # Exibe resultados formatados
    print(f"Success: {result.get('success')}")
    # ...
```

**Benef√≠cio:** Pode executar `python main.py` diretamente para testar.

---

## Arquivos Criados

### 1. `.env.config` (Template)
Template de configura√ß√£o com exemplo de credenciais.

### 2. `.gitignore`
```
.env
__pycache__/
*.pyc
venv/
```

### 3. `test_local.py`
Script de teste completo que:
- Verifica se `.env` existe
- Executa m√∫ltiplos testes (busca livre e por campos)
- Exibe resultados formatados

### 4. Documenta√ß√£o
- `README.md` - Guia sucinto quick start
- `MODIFICACOES_LOCAL.md` - Este arquivo
- `PYTHON_SETUP.md` - Setup Python 3.10/3.11
- `INSTALL.md` - Troubleshooting instala√ß√£o

---

## üîÑ Fluxo de Execu√ß√£o Local

```mermaid
graph TD
    A[python test_local.py] --> B[Carrega .env]
    B --> C[Define WHO_IS_RUNNING_THIS=local]
    C --> D[Importa gold.busca.main]
    D --> E{Bugsnag dispon√≠vel?}
    E -->|N√£o| F[Usa MockBugsnag]
    E -->|Sim| G[Usa Bugsnag real]
    F --> H[Carrega semantic_search]
    G --> H
    H --> I[Conecta VectorSearchClient com .env]
    I --> J[Executa consolidation_function]
    J --> K[Retorna resultados]
```

---

## Compatibilidade Mantida

Todas as modifica√ß√µes mant√™m compatibilidade com os modos originais:

| Modo | Configura√ß√£o | Funcionamento |
|------|--------------|---------------|
| `ENDPOINT_NOTEBOOK` | Databricks Notebook | Mantido (usa imports originais) |
| `ENDPOINT_MLFLOW` | MLflow Endpoint | Mantido (usa imports originais) |
| `local` | **NOVO** - Via .env | Adicionado |

**Nenhuma linha de c√≥digo dos modos originais foi removida!**

---

## Seguran√ßa

### Credenciais
- ‚úÖ `.env` est√° no `.gitignore`
- ‚úÖ `.env.example` √© apenas template (sem credenciais reais)
- ‚úÖ C√≥digo valida se credenciais est√£o presentes

---

## Resumo das Depend√™ncias

### Originais (Databricks)
```
pandas
databricks-vectorsearch
databricks-langchain
rapidfuzz
```

### Adicionadas para Local
```
python-dotenv  # Carregar .env
```

### Removidas/Opcionais
```
bugsnag  # Agora opcional
boto3    # N√£o necess√°rio
```

---

